(window.webpackJsonp=window.webpackJsonp||[]).push([[43],{657:function(s,a,e){"use strict";e.r(a);var n=e(4),t=Object(n.a)({},(function(){var s=this,a=s.$createElement,e=s._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[e("h2",{attrs:{id:"概述"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#概述"}},[s._v("#")]),s._v(" 概述")]),s._v(" "),e("p",[s._v("kafka是分布式基于的消息队列，"),e("strong",[s._v("实时处理")])]),s._v(" "),e("h2",{attrs:{id:"入门"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#入门"}},[s._v("#")]),s._v(" 入门")]),s._v(" "),e("ul",[e("li",[s._v("特点")]),s._v(" "),e("li",[s._v("发布订阅模式\n"),e("ul",[e("li",[s._v("消费者拉取（比较费支援，维护长时轮询）")]),s._v(" "),e("li",[s._v("管道主动推送 (消费者处理不即)")])])])]),s._v(" "),e("h2",{attrs:{id:"架构💨💨"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#架构💨💨"}},[s._v("#")]),s._v(" 架构💨💨")]),s._v(" "),e("p",[e("img",{attrs:{src:"https://gitee.com/axcmsm/tmp/raw/master/bigdata/20210917174303.png",alt:""}})]),s._v(" "),e("ul",[e("li",[s._v("生产者消息")]),s._v(" "),e("li",[s._v("kakfa集群管理消息（borker主机，主题，分类，分区(提高鬓发度),小弟用来备份副本树算上老大 ）")]),s._v(" "),e("li",[s._v("消费者消费信息（消费者组，消费者(某个分区只能由"),e("strong",[s._v("同组")]),s._v("其中一个消费)")]),s._v(" "),e("li",[s._v("zookeeper(管理注册信息)")])]),s._v(" "),e("blockquote",[e("p",[s._v("在0.9之前offset(消息偏移量)存储在zk中")]),s._v(" "),e("p",[s._v("0.9之后存储在本地kafka(系统的)")]),s._v(" "),e("p",[s._v("主要是记录消费位置，防止挂掉")]),s._v(" "),e("p",[s._v("消费者是以拉取获取模式(速度快,要跟zk打交道,所以太过频繁了，高并发)")]),s._v(" "),e("p",[s._v("所以存储到kafka本地里面，kafka默认存消息在磁盘(默认保留7天(168小时))")])]),s._v(" "),e("h2",{attrs:{id:"安装部署"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#安装部署"}},[s._v("#")]),s._v(" 安装部署")]),s._v(" "),e("p",[s._v("集群规划：3台zk 3台kafka")]),s._v(" "),e("p",[s._v("修改:service配置文件 把borck.id改成为唯一 然后分发集群")]),s._v(" "),e("p",[s._v("启动  -daemon表示以守护进程来启动")]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v("/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br")])]),e("p",[e("strong",[s._v("命令行操作")]),s._v("：topic（CRUD）")]),s._v(" "),e("ul",[e("li",[s._v("--list 查看")])]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v("./bin/kafka-topics.sh --list --zookeeper hadoop111:2181\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br")])]),e("ul",[e("li",[e("p",[s._v("往zk里创建数据 --create  需要指定topic主题 partitions分区个数  副本个数replication-factor")]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v("./bin/kafka-topics.sh --create --zookeeper hadoop111:2181 --topic first --partitions 2 --replication-factor 2\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br")])]),e("blockquote",[e("p",[s._v("然后查看在你配置的logs目录里 就可以查看到创建的目录了 所以是放在磁盘的")]),s._v(" "),e("p",[s._v("而且存放目录名 由主题+分区构成,启动日志到server.log查看")]),s._v(" "),e("p",[s._v("默认是50个分区 一个副本")])])]),s._v(" "),e("li",[e("p",[s._v("-detele删除")]),s._v(" "),e("div",{staticClass:"language-shell line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[s._v(" ./bin/kafka-topics.sh --delete --zookeeper hadoop111:2181 --topic first\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br")])]),e("blockquote",[e("p",[s._v("如果设置了"),e("code",[s._v("delete.topic.enable 为true")]),s._v(" 才能真正删除")])])]),s._v(" "),e("li",[e("p",[s._v("describe 查看结构详细信息")]),s._v(" "),e("div",{staticClass:"language-shell line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[s._v("./bin/kafka-topics.sh --describe --topic first --zookeeper hadoop111:2181\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#")]),s._v("\nTopic:first\tPartitionCount:2\tReplicationFactor:2\tConfigs:\n\tTopic: first\tPartition: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\tLeader: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\tReplicas: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("2,1")]),s._v("\tIsr: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("2,1")]),s._v("\n\tTopic: first\tPartition: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\tLeader: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\tReplicas: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3,2")]),s._v("\tIsr: "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3,2")]),s._v("\n\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br")])])])]),s._v(" "),e("p",[e("strong",[s._v("生产者消费者")]),s._v("："),e("code",[s._v("console-producer.sh生产者 ``console-consumer.sh消费者")])]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v(" #生产者9092端口 主题topic 区域broker\n ./bin/kafka-console-producer.sh --topic first --broker-list hadoop111:9092\n #消费者\n 老版本是连接到zk,0.9版本后是存储到本地\n./bin/kafka-console-consumer.sh --topic first --zookeeper  hadoop111:2181 #老版本\n./bin/kafka-console-consumer.sh --topic first --zookeeper  hadoop111:2181 --from-beginning 表示从开头的管道开始获取\n\n#新版启动 消息存储本地kafka,而kafka存储到logs中的主题offset偏移量\n./bin/kafka-console-consumer.sh --topic first --bootstrap-server  hadoop111:9092\n\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br")])]),e("p",[s._v("删除数据除了删除kafka存储信息的目录还要删除zk中存储的位置信息zookeeper是默认目录")]),s._v(" "),e("p",[s._v("重装zk数据(慎重)")]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v("[hadoop101@axcmsm111 zkData]$ ll\n总用量 8\n-rw-rw-r--. 1 hadoop101 hadoop101   2 9月   4 17:36 myid #\ndrwxrwxr-x. 2 hadoop101 hadoop101 162 9月  15 12:04 version-2 #数据信息\n-rw-rw-r--. 1 hadoop101 hadoop101   4 9月  15 12:04 zookeeper_server.pid #进程\n[hadoop101@axcmsm112 zkData]$ rm -rf version-2/  #删除所有数据\n#重启查看\n[zk: localhost:2181(CONNECTED) 0] ls /\n[zookeeper]\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br")])]),e("p",[s._v("工作流程：")]),s._v(" "),e("p",[s._v("生产者生成数据，发送到kafka机器,机器中的每台机器，都有一个leader主题,里面由分区，消费者消费时存储的offset偏移量默认从0开始,还有对应的副本,且副本小弟一般跨机器放置,不然没意义。然后再到消费者组对其相应的机器主题来拉取数据。(都是面向主题的topic逻辑概念) 因为实际存储文件是主题+分区号的文件")]),s._v(" "),e("p",[e("img",{attrs:{src:"https://gitee.com/axcmsm/tmp/raw/master/bigdata/image-20210915205600566.png",alt:""}})]),s._v(" "),e("p",[s._v("不能保证全局有序，只能保证区内有序")]),s._v(" "),e("p",[s._v("存储数据的文件: 采用"),e("strong",[s._v("分片")]),s._v("和"),e("strong",[s._v("索引")]),s._v("的处理机制  (虽然存储到磁盘当中,但利用索引二分查找还是挺快的)")]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v("[hadoop101@axcmsm111 first-0]$ ll\n总用量 0\n-rw-rw-r--. 1 hadoop101 hadoop101 10485760 9月  15 21:04 00000000000000000000.index\n-rw-rw-r--. 1 hadoop101 hadoop101        0 9月  15 21:04 00000000000000000000.log\n-rw-rw-r--. 1 hadoop101 hadoop101 10485756 9月  15 21:04 00000000000000000000.timeindex\n-rw-rw-r--. 1 hadoop101 hadoop101        0 9月  15 21:04 leader-epoch-checkpoint\n#默认log默认设置的大小是1G 超过就会创建一个新文件\nxxx.log 只存数据  \nxxx.index 记录log索引便新建文件时继续输入\n前面的xxx是记录当前文件的最小偏移量\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br")])]),e("p",[e("strong",[s._v("分区策略")]),s._v(":")]),s._v(" "),e("p",[s._v("数据封装成prodgeerRecord对象发送")]),s._v(" "),e("p",[s._v("可指定分区号、主题、头信息等,如果输入kv的话k作为hash%%主题的分区个数得到分区值，什么都不指定，就进行轮询")]),s._v(" "),e("p",[e("strong",[s._v("数据可靠性")]),s._v(":ISR(同步队列)")]),s._v(" "),e("p",[s._v("通过规定完成相应的机器队列（时间），就可以发送数据,如果leater挂了 直接在队列里选leater")]),s._v(" "),e("p",[s._v("队列选举移除了条数选项,isr占内存,而且是批次的,所以老队员会被踢出来，再选举再进入,频繁操作isr,zk耗费资源")]),s._v(" "),e("p",[s._v("ack"),e("strong",[s._v("应答机制")]),s._v(":提供了三种级别 根据可靠性和演出进行权衡")]),s._v(" "),e("ul",[e("li",[s._v("acks: 0不等待 1等待leater  all(-1) 等待leater和isr里面的(当isr同步完数据还每发ack时leader挂了会重新选举，重新发送数据，造成数据重复)")]),s._v(" "),e("li",[s._v("一致性：HW（高匹配 消费一致性）leo（最后一个offset 存储一致性）:hw之前才对消费者可见,不然的用offset的话会报错")])]),s._v(" "),e("p",[e("strong",[s._v("EXACTLYonce")]),s._v("  精准一次性消费（不重复，不丢失）")]),s._v(" "),e("ul",[e("li",[s._v("最少一次+幂等性=精准一次性")]),s._v(" "),e("li",[s._v("开启幂等性 默认ack为-1, 用pid,分区,切片位置进行缓存")]),s._v(" "),e("li",[s._v("只能解决单个会话，单次分区的数据重复问题(重启不行 )")])]),s._v(" "),e("p",[e("strong",[s._v("消费者")])]),s._v(" "),e("p",[s._v("consumer采用pull到broker中读取数据")]),s._v(" "),e("p",[e("strong",[s._v("分区分配策略")]),s._v("：可同时消费一个,多个主题，不能同时消费一个分区")]),s._v(" "),e("ul",[e("li",[e("p",[s._v("轮询 RoundRobin (把消费者祖里面的所有主题当作一个主题，进行轮询)   按照组划分")]),s._v(" "),e("blockquote",[e("p",[s._v("所以需要前提条件保证当前消费者组里的消费者订阅的主题的一样的")])])]),s._v(" "),e("li",[e("p",[s._v("范围 Range（默认） 按照单个主题划分的")])])]),s._v(" "),e("p",[s._v("当消费者组里面数量发送变化就会触发重新分配")]),s._v(" "),e("p",[e("strong",[s._v("offset维护")])]),s._v(" "),e("p",[s._v("保存到zk 组 主题 分区")]),s._v(" "),e("p",[e("strong",[s._v("事务")]),s._v("：(生产者)结合幂等性 解决精准一次写入kafka集群,加上事务能保证跨分区")]),s._v(" "),e("h2",{attrs:{id:"api⭕⭕"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#api⭕⭕"}},[s._v("#")]),s._v(" API⭕⭕")]),s._v(" "),e("p",[e("strong",[s._v("生产者")]),s._v(":异步发送 俩个线程 main和sender线程、共享变量线程RecordAccomalator")]),s._v(" "),e("ul",[e("li",[s._v("同步get")]),s._v(" "),e("li",[s._v("回调函数new Callback()")]),s._v(" "),e("li",[s._v("自定义拦截器")])]),s._v(" "),e("p",[e("strong",[s._v("消费者")]),s._v("：")]),s._v(" "),e("ul",[e("li",[s._v("自动提取offset")]),s._v(" "),e("li",[s._v("手动提交offset")]),s._v(" "),e("li",[s._v("自定义存储offset")])]),s._v(" "),e("h2",{attrs:{id:"对接flume"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#对接flume"}},[s._v("#")]),s._v(" 对接Flume")]),s._v(" "),e("p",[e("strong",[s._v("步骤")]),s._v("：")]),s._v(" "),e("ul",[e("li",[e("p",[s._v("配置flume配置文件")]),s._v(" "),e("div",{staticClass:"language-conf line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v("# define\na1.sources = r1\na1.sinks = k1\na1.channels = c1\n# source\na1.sources.r1.type = exec\na1.sources.r1.command = tail -F -c +0 /opt/module/data/flume.log\na1.sources.r1.shell = /bin/bash -c\n# sink\na1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink\na1.sinks.k1.kafka.bootstrap.servers = \nhadoop102:9092,hadoop103:9092,hadoop104:9092\na1.sinks.k1.kafka.topic = first\na1.sinks.k1.kafka.flumeBatchSize = 20\na1.sinks.k1.kafka.producer.acks = 1\na1.sinks.k1.kafka.producer.linger.ms = 1\n# channel\na1.channels.c1.type = memory\na1.channels.c1.capacity = 1000\na1.channels.c1.transactionCapacity = 100\n# bind\na1.sources.r1.channels = c1\na1.sinks.k1.channel = c1\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br"),e("span",{staticClass:"line-number"},[s._v("13")]),e("br"),e("span",{staticClass:"line-number"},[s._v("14")]),e("br"),e("span",{staticClass:"line-number"},[s._v("15")]),e("br"),e("span",{staticClass:"line-number"},[s._v("16")]),e("br"),e("span",{staticClass:"line-number"},[s._v("17")]),e("br"),e("span",{staticClass:"line-number"},[s._v("18")]),e("br"),e("span",{staticClass:"line-number"},[s._v("19")]),e("br"),e("span",{staticClass:"line-number"},[s._v("20")]),e("br"),e("span",{staticClass:"line-number"},[s._v("21")]),e("br"),e("span",{staticClass:"line-number"},[s._v("22")]),e("br"),e("span",{staticClass:"line-number"},[s._v("23")]),e("br")])])]),s._v(" "),e("li",[e("p",[e("strong",[s._v("启动")]),s._v(" "),e("strong",[s._v("kafkaIDEA")]),s._v(" "),e("strong",[s._v("消费者")])])]),s._v(" "),e("li",[e("p",[e("strong",[s._v("进入")]),s._v(" "),e("strong",[s._v("flume")]),s._v(" "),e("strong",[s._v("根目录下，启动")]),s._v(" "),e("strong",[s._v("flume")])]),s._v(" "),e("div",{staticClass:"language-shell line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[s._v(" bin/flume-ng agent -c conf/ -n a1 -f jobs/flume-kafka.conf\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br")])])]),s._v(" "),e("li",[e("p",[e("strong",[s._v("向")]),s._v(" "),e("strong",[s._v("/opt/module/data/flume.log")]),s._v(" "),e("strong",[s._v("里追加数据，查看")]),s._v(" "),e("strong",[s._v("kafka")]),s._v(" "),e("strong",[s._v("消费者消费情况")])]),s._v(" "),e("div",{staticClass:"language-shell line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[s._v(" "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("echo")]),s._v(" hello "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),s._v(" /opt/module/data/flume.log\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br")])])])])])}),[],!1,null,null,null);a.default=t.exports}}]);